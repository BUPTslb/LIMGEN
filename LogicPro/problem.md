# 问题
## 一些工程问题
Git上传文件夹方法总结：  
首先保证能够连接到GitHub：ssh -T git@github.com，记得输入yes
## 重写DES算法，化简
multiple definition of：  
不要把全局变量及全局方法的定义放在头文件。  
-测试LLVM的CDFG图生成能力
使用测试函数，testgraph.cpp
llvm生成call graph和DFG的脚本：  
`clang $1.c -emit-llvm -S //生成IR`   
`opt -dot-cfg $1.ll > /dev/null  //生成CFG`
`opt -dot-callgraph $1.ll > /dev/null`  
`dot -Tpng -o $1.png cfg.main.dot`  
`dot -Tpng -o $1.callgraph.png callgraph.dot`  
`clang -S $1.c -o $1.s //生成汇编代码`  
**当前无法使用LLVM生成CDFG**  
[clang参数](https://www.jianshu.com/p/96058bf1ecc2)  
-双系统ubuntu无法访问其他盘，使用如下命令  
sudo  ntfsfix /dev/sda3  
在此之前要安装NTFSfix：sudo apt install ntfs-3g -y  
-typedef struct含义：定义结构体的名称  
-int main(int argc, char* argv[])  
argc为程序运行时候发送给main函数的命令行参数的个数，在VS中默认值为1  
char*型的argv[]，为字符串数组，用来存放指向的字符串参数的指针数组，每一个元素指向一个参数。各成员含义如下：  
argv[0]指向程序运行的全路径名  
argv[1]指向在DOS命令行中执行程序名后的第一个字符串  
argv[2]指向执行程序名后的第二个字符串  
argv[3]指向执行程序名后的第三个字符串  
argv[argc]为NULL  
-char[]与char*的定义  
char[]是字符数组，可以{,,,}定义，“”定义时数量比数字小1,末尾默认为0  
\*指针只有const char*能直接用字符串定义，其余的指向定义的空间即可-
## 生成算法的CDFG图
### 从LLVM IR到CDFG
首先将Sampledes编译成LLVM IR
clang++ -S -emit-llvm desSample.cpp -o desSample.ll -O3
473行
生成汇编代码
clang++ -S desSample.cpp -o desSample.s
800行
用完整的一个应用/高级算法生成CDFG大概率看不懂，应该从小函数开始，可以选择向量相加
-opt: unknown pass name 'dot-callgraph'
似乎和版本有关，暂时找不到生成以算子为节点的方法。  

**11月5日，放弃使用LLVM作为前端**
1. 从使用高级语言作为输入的HLS论文中找CDFG生成方法，基本没有详细介绍
2. 从HDL语言开始生成CDFG 这里容易被吐槽与现有高层次综合不太一样
-安装版本的LLVM似乎存在很多工具缺失，重新进行编译版本的LLVM 
使用其DAG图生成功能：
llc -mtriple=mips-linux-gnu –view-dag-combine1-dags sum.ll
-发现一个NYU的做CGRA的
其中工具包含使用LLVM pass生成CDFG，无果而终

### 从VHDL到CDFG
南佛洛丽达大学的毕业论文CHESS  
香港理工大学毕业论文中提到一个工具Hardware Petri Nets：通过佩特里网生成CDFG,P71/114  
   上文说chess严重依赖VHDL高级语法，而我们设定了编程模型，不用考虑通用型问题，因此证明CHESS可用
CHESS：
1. 词法分析lexical analysis
   将源程序转换为标记流，其中每个标记是具有集体意义的字符序列，如标识符、关键字、操作符或标点符号
   使用Lex,生成tokens
   编译命令：
   flex example1.l
   cc lex.yy –o example –lfl
   生成可执行文件example，-lfl是编译选项，没有定义main函数时候使用
2. 语法分析
   对它们施加层次结构，以验证程序的语法
   使用YACC,YACC程序包含显式函数，用于在语法层次结构中的每个步骤创建节点
   YACC可以解析输入流中的标识符(token)，生成解析树
3. 截断 解析树【truncate(parse tree)】
   解析树压缩成为语法树，语法树变换为CDFG  

词法分析和句法分析即使是对于VHDL也是一个比较复杂的工作，而且已经有较多的反编译前端现有工具，他们的目的是从HDL生成高级语言，中间会生成AST，不必去做重复的工作，可以参考的Github：https://github.com/Nic30/hdlConvertor  
上述工具得到VHDL的AST，我们要做的工作就是将AST转化为CDFG，依据：CHESS中的算法  
**当前目的**
读懂python代码，分析抽象语法树的结构，从中抽取出算子，绘制CDFG




### 设定编程模型
选择使用能够描述行为级的硬件描述语言VHDL，Verilog级别相对低级，适合描述RTL。  
在写VHDL时，使用architecture Behavioral of XXX is，结构体的行为命名，对应行为级描述。采用进程语句顺序描述实体行为，抽象程度高，大量使用逻辑运算（算术运算、关系运算），为高层次描述，不用关注电路组织和门级实现。  
我们决定规定只能使用硬件相关的算子进行编程,类似于Rolf Drechsler的论文LIM-HDL。  
其中支持的算子有：RM3,&，|，～，^，由于这篇文章是基于PLIM架构的，有MAJ操作，我们的逻辑组中使用MAGIC，将RM3更换为NOR。  
常见的逻辑操作之 shift：文中没有给转换，因为有语义意义--最终图中的操作数与操作的连接（**这一点不太理解**）  
另外存在LUT可以进行其他操作。
算子支持：
1. 外围电路SA：XOR、OR、AND、INV（只处理行间操作）
2. RRAM性质，基于MAGIC逻辑族：NOR（只处理行内操作）
由于底层都是逻辑算子，必然会有常用而且无法解决的情况，我们选择使用LUT来弥补
3. 基于LUT：常用的、无法用以上算子综合的算子
使用以上算子对算法重新书写，写成VHDL语言




## 高层次综合
输入：算法级行为描述、约束条件和目标集合  
输出：在目标集合中找到一个满足约束条件，实现系统行为的**结构**  
行为：系统与外界的作用和联系（如输入到输出的映射关系）  
结构：组成系统的部件和他们的连接关系   
1. 确定内部表示
注意，高层次综合并不能对算法进行优化，算法的实现直接导致了蕴含的硬件代价不同，在进行高层次综合之前，使用者应该确定一个较优的算法  
高层次综合面向的是一个算法，使用CDFG方便、直观的表示，表示为一个有向图G=<V,E>  
2. 确定约束条件
在约束条件的指导下，在满足约束条件的范围内选择方案，缩小设计空间的范围。  
时间约束：允许的最大延迟；代价约束：硬件资源种类、数量、面积
3. 算子调度
   目的：最大程度的复用资源（注：我认为这一点存算一体中会有不同的体现）  
   提高资源复用率的方法：每一个控制步中同类型的算子数量尽量平均。  
   在存算一体中，有这样一种计算特点：在使用外围电路SA执行逻辑计算时，必须先将计算的数据写入阵列的行中，然后再计算，由于行、列由公用的WL\SL连接，做存算设备时，阵列的读、写、计算操作要分开单独执行，即同一时间只能执行三种之一，其中写操作占的时间最长。由于表示数据的是电阻，单纯将阵列当做计算单元时，也无法避免要先进行写操作。这种特性会影响算子调度：  
   经过推导，这种运算方式只能将所有相关的数据写进同一阵列中，然后按照其运算方式串行进行，即基本不能进行算子调度，如果要运用中间结果与存的数据进行再次运算，可以修改SA，用寄存器存储中间结果，跟传来的数据进行运算。  
   【如何使用中间结果，如何将相关的数据写入同一个阵列，并且考虑中间结果，使得计算所需的资源数量更少或者速度更快，存在调度】  
   【要尽可能的发挥存算一体的大规模并行性】  
   与之相关但不同的，MAGIC模式可以直接将中间结果写到一整列RRAM中，不用写回，但用阵列当做大规模NOR还是综合好当做计算器件，这一点需要分析。  
   在DUT的论文中提到，常规HLS步骤用在CIM（MAGIC）上不合理，因为布局布线和调度存在循环依赖关系：调度应该最早进行，但是调度需要布局布线的结果：即传输时延信息
   至于LUT模式，可以当做常用算子的加速器，因为其可以实现任何逻辑，但是其缺点是什么？是并行性不如另外两种操作吗？这点仍需要分析，**三种逻辑读、写、计算的特点，好处、劣势，需要详细的对比**


 3.1 基本概念  
 控制步：为了实现资源复用，对算法进行步骤划分，类似周期cycle。  
 关键路径：CDFG上最长的路径。决定时间特性，关键路径上的操作有严格的先后顺序，必须占据不同的控制步，不考虑资源约束时候，关键路径长度是系统最优时间特性的一个度量  
 依赖关系：算子调度要把操作安排到控制步上，但是要满足先后依赖关系，不能任意分配
 3.2 调度与时间特性评估  
 ASAP、ALAP算子调度方案不用于最终实现，而是进行时间特性评估，指导设计优化方向  
 两种调度方案对于一个算法来说是唯一的，**给出了最优的时间特性，给出了关键路径**。  
 没有考虑资源限制，但能得出算子的机动性：算子能够在控制步中最前和最后的位置，任何调度方案都不能跨越这一范围。可以指导设计空间的大小  
 **即：所有调度方案的数量不会超过算子机动性的乘积。在考虑数据依赖关系后，比如ab有依赖关系，a确定，b机动性就进一步减小，设计空间进一步减小**
 3.3 表格调度算法  
 算子调度：将算子放进控制步骤，包含【选择算子】和【安排控制步】两个步骤  
 表格调度算法侧重于【确定算子被安排的顺序】，安排好后控制步安排越早越好  
 核心：确定算子优先级，这里的优先级函数有多种。  
   （1）按算子出现的顺序
   （2）算子到CDFG底部出口的路径长度，越长优先级越高
   （3）算子机动性，机动性小的优先级大，先被安排
 3.4 分支与边界调度算法  
 穷举，列出所有方案（中间明显不好的方案剪去），生成调度树，从中选择最优。按照控制步的顺序进行穷举。  
 缺点：时间复杂度太大（指数级别），需要的存储较大  
 3.5 力量引导调度  
 即选择算子，又选择控制步。
 最好的，唯一能够保证调度最优性质的算子调度方案。  
 一个控制步中的算子较多，压力就大，对算子的斥力就大。算子总是应该位于对其斥力最小或者引力最大的控制步中。  
 减小工作量：关键路径上的算子，机动性为1，无法移动，以此为基础，考虑非关键路径上算子的调度，非关键路经上也只需要考虑可以机动的控制步骤。  







 



## 当前的问题
-CDFG-：  
使用存内计算时必须先将两个操作数写进同一个阵列中，计算完之后的中间结果如果需要再和其他操作数执行运算，则需要再写回，但RRAM存在写效率低的问题，而且一个阵列同一时间只能串行使用SA，读、写、执行运算都会占用SA，相当于很多操作数都只能单发射串行，效率很低下且有写耐久问题、阵列大小限制。  
如果放进其他阵列处理，则更慢且不会减小写次数，唯一好处就是分担了耐久。这个问题是当前遇到的最大问题。